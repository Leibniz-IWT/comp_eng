{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfd7799a",
   "metadata": {},
   "source": [
    "# Chapter 8: Non-linear Optimization\n",
    "\n",
    "## Introduction: Why Non-linear Optimization in Engineering?\n",
    "[Brief overview: NLPs for real-world problems like spacecraft trajectory design, where objectives/constraints are non-linear. Link to Chapter 7 (convex cases) and forward to global opt (Chapter 9) and control (Chapters 10â€“14).]\n",
    "\n",
    "## Non-linear Programming Problems (NLPs)\n",
    "[Introduction and formal definition: \\(\\min_{\\mathbf{x} \\in \\mathcal{X}} f(\\mathbf{x})\\) s.t. \\(\\mathbf{g}(\\mathbf{x}) \\leq \\mathbf{0}\\), \\(\\mathbf{h}(\\mathbf{x}) = \\mathbf{0}\\).]\n",
    "[Contrast with Chapter 7: Extending unconstrained methods to general constrained NLPs, focusing on local minima.]\n",
    "\n",
    "### KKT Conditions\n",
    "[Introduction, formal definition (primal/dual feasibility, stationarity, complementarity), graphical demonstration with Matplotlib contours.]\n",
    "[Python example: Symbolic KKT with SymPy on a quadratic program.]\n",
    "\n",
    "### Trust-Region Methods\n",
    "[Detailed outline: Quadratic subproblems, trust radius updates, convergence.]\n",
    "[Algorithm pseudocode.]\n",
    "[Basic Python implementation (NumPy/SciPy) and numerical example (e.g., Rosenbrock function with iteration plots).]\n",
    "\n",
    "### Sequential Quadratic Programming (SQP) with `scipy.optimize.minimize`\n",
    "[Introduction: Approximating NLPs via QP subproblems, link to trust-regions.]\n",
    "[Method outline: Hessian approximation, line search.]\n",
    "[Basic example: `minimize(method='SLSQP')` on a constrained space engineering problem (e.g., optimal thrust allocation).]\n",
    "\n",
    "## Non-linear Least-Squares (NLLS)\n",
    "[Formal definition: Minimizing squared residuals for data fitting.]\n",
    "[Introduction to data-based methods: Modern ML examples (e.g., regression for satellite data), Python example with `scipy.optimize.least_squares`.]\n",
    "[Connecting data sampling to optimization spaces: Bridge to ML, where training minimizes loss over datasets.]\n",
    "\n",
    "## Backpropagation in Neural Networks\n",
    "[Develop NN as a parametric non-linear model: Example of a single node's activation function.]\n",
    "[Formal definition of NN architectures: \\(\\mathbf{y} = \\mathbf{f}(\\mathbf{x}; \\mathbf{W}, \\mathbf{b})\\).]\n",
    "[Backpropagation in optimization context: Chain rule for gradients, use in minimizing loss.]\n",
    "[Python example: Simple NumPy backprop on a feedforward NN.]\n",
    "[State-of-the-art libraries: scikit-learn for ML basics, TensorFlow/PyTorch for DL (install via pip if needed).]\n",
    "\n",
    "## Stochastic Gradient Descent (SGD)\n",
    "[Introduction to noisy objective functions: Handling large/uncertain data (e.g., in space mission planning).]\n",
    "[Formal definitions, outline of SGD methods (mini-batches, momentum).]\n",
    "[Performance, limitations, and comparisons to deterministic methods.]\n",
    "[Python example: NumPy SGD on a noisy objective, with scikit-learn integration.]\n",
    "\n",
    "## Exercises and Further Applications\n",
    "[Interactive problems: e.g., Modify SQP example for orbit optimization; implement backprop for a simple controller.]\n",
    "[Further reading: Nocedal & Wright (optimization), Goodfellow et al. (DL).]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5a095f2b4e7006e2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
